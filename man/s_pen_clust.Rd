% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/simulation_functions.R
\name{s_pen_clust}
\alias{s_pen_clust}
\title{Fit Penalized Regression Models on Simulated Cluster Summaries}
\usage{
s_pen_clust(x_train, x_test, y_train, y_test, s0, gene_groups,
  summary = c("pc", "avg"), model = c("lasso", "elasticnet", "scad", "mcp"),
  exp_family = c("gaussian", "binomial"), filter = F, topgenes = NULL,
  stability = F, include_E = T, include_interaction = T,
  clust_type = c("CLUST", "ECLUST"), number_pc = 1)
}
\arguments{
\item{x_train}{\code{ntrain x p} matrix of simulated training set where
\code{ntrain} is the number of training observations  and \code{p} is total
number of predictors. This matrix needs to have named columns representing
the feature names or the gene names}

\item{x_test}{\code{ntest x p} matrix of simulated training set where
\code{ntest} is the number of training observations  and \code{p} is total
number of predictors. This matrix needs to have named columns representing
the feature names or the gene names}

\item{y_train}{numeric vector of length \code{ntrain} representing the
responses for the training subjects. If continuous then you must set
\code{exp_family = "gaussion"}. For \code{exp_family="binomial"} should be
either a factor with two levels, or a two-column matrix of counts or
proportions (the second column is treated as the target class; for a
factor, the last level in alphabetical order is the target class)}

\item{y_test}{numeric vector of length \code{ntest} representing the
responses for the test subjects. If continuous then you must set
\code{exp_family = "gaussion"}. For \code{exp_family="binomial"} should be
either a factor with two levels, or a two-column matrix of counts or
proportions (the second column is treated as the target class; for a
factor, the last level in alphabetical order is the target class).}

\item{s0}{chracter vector of the active feature names, i.e., the features in
\code{x_train} that are truly associated with the response.}

\item{gene_groups}{data.frame that contains the group membership for each
feature. The first column is called 'gene' and the second column should be
called 'cluster'. The 'gene' column identifies the features and must be the
same identifiers in the \code{x_train,x_test} matrices. The 'cluster'
column is a numeric integer indicating the cluster group membership.  A
cluster group membership of 0 implies the feature did not cluster into any
group.}

\item{summary}{the summary of each cluster. Can be the principal component or
average. Default is \code{summary = "pc"} which takes the first
\code{number_pc} principal components. Currently a maximum of 2 principal
components can be chosen.}

\item{model}{Regression model to be fit on cluster summaries. Default is
\code{model="lasso"} which corresponds to glmnet mixing parameter
\code{alpha=1}. \code{model="elasticnet"} corresponds to glmnet mixing
parameter \code{alpha=0.5}, \code{model="mcp"} and \code{model="scad"} are
the non-convex models from the \code{\link[ncvreg]{}} package}

\item{exp_family}{Response type. See details for \code{y_train} argument
above.}

\item{filter}{Should analysis be run on a subset of features. Default is
\code{filter = FALSE}}

\item{topgenes}{List of features to keep if \code{filter=TRUE}. Default is
\code{topgenes = NULL} which means all features are kept for the analysis}

\item{stability}{Should stability measures be calculated. Default is
\code{stability=FALSE}. See details}

\item{include_E}{Should the environment variable be included in the
regression analysis. Default is \code{include_E = TRUE}}

\item{include_interaction}{Should interaction effects between the features in
\code{x_train} and the environment variable be fit. Default is
\code{include_interaction=TRUE}}

\item{clust_type}{Method used to cluster the features. This is used for
naming the output only and has no consequence for the results.
\code{clust_type = "CLUST"} is the default which means that the environment
varible was not used in the clustering step. \code{clust_type = "ECLUST"}
means that the environment variable was used in the clustering aspect.}

\item{number_pc}{Number of principal components if \code{summary = "pc"}.
Default is \code{number_pc = 1}. Can be either 1 or 2.}
}
\value{
This function has two different outputs depending on whether
  \code{stability = TRUE} or \code{stability = FALSE}

  If \code{stability = TRUE} then this function returns a \code{p x 2}
  data.frame or data.table of regression coefficients without the intercept.
  The output of this is used for subsequent calculations of stability.

  If \code{stability = FALSE} then returns a vector with the following
  elements (See Table 3: Measures of Performance in Bhatnagar et al (2016+)
  for definitions of each measure of performance): \item{mse or AUC}{Test set
  mean squared error if \code{exp_family = "gaussion"} or test set Area under
  the curve if \code{exp_family = "binomial"} calculated using the
  \code{\link[pROC]{roc}} function} \item{RMSE}{Square root of the mse. Only
  applicable if \code{exp_family = "gaussion"}} \item{Shat}{Number of
  non-zero estimated regression coefficients. The non-zero estimated
  regression coefficients are referred to as being selected by the model}
  \item{TPR}{true positive rate} \item{FPR}{false positive rate}
  \item{Correct Sparsity}{Correct true positives + correct true negative
  coefficients divided by the total number of features}
  \item{CorrectZeroMain}{Proportion of correct true negative main effects}
  \item{CorrectZeroInter}{Proportion of correct true negative interactions}
  \item{IncorrectZeroMain}{Proportion of incorrect true negative main
  effects} \item{IncorrectZeroInter}{Proportion of incorrect true negative
  interaction effects} \item{nclusters}{number of estimated clusters by the
  \code{\link[dynamicTreeCut]{cutreeDynamic}} function}
}
\description{
This function creates summaries of the given clusters (e.g. 1st
  PC or average), and then fits a penalized regression model on those
  summaries. To be used with simulated data where the 'truth' is known i.e.,
  you know which features are associated with the response. This function was
  used to produce the simulation results in Bhatnagar et al. 2016. Can run
  lasso, elasticnet, SCAD or MCP models
}
\details{
The stability of feature importance is defined as the variability of
  feature weights under perturbations of the training set, i.e., small
  modifications in the training set should not lead to considerable changes
  in the set of important covariates (Toloşi, L., & Lengauer, T. (2011)). A
  feature selection algorithm produces a weight, a ranking, and a subset of
  features. In the CLUST and ECLUST methods, we defined a predictor to be
  non-zero if its corresponding cluster representative weight was non-zero.
  Using 10-fold cross validation (CV), we evaluated the similarity between
  two features and their rankings using Pearson and Spearman correlation,
  respectively. For each CV fold we re-ran the models and took the average
  Pearson/Spearman correlation of the 10 choose 2 combinations of estimated
  coefficients vectors. To measure the similarity between two subsets of
  features we took the average of the Jaccard distance in each fold. A
  Jaccard distance of 1 indicates perfect agreement between two sets while no
  agreement will result in a distance of 0.
}
\note{
\code{number_pc=2} will not work if there is only one feature in an
  estimated cluster
}
\examples{

}
\references{
Toloşi, L., & Lengauer, T. (2011). \emph{Classification with
  correlated features: unreliability of feature ranking and solutions.
  Bioinformatics, 27(14), 1986-1994.}

Bhatnagar, SR., Yang, Y., Blanchette, M., Bouchard, L.,
  Khundrakpam, B., Evans, A., Greenwood, CMT. (2016+). \emph{An analytic
  approach for interpretable predictive models in high dimensional data, in
  the presence of interactions with exposures
  \href{http://sahirbhatnagar.com/slides/manuscript1_SB_v4.pdf}{Preprint}}

Langfelder, P., Zhang, B., & Horvath, S. (2008). \emph{Defining
  clusters from a hierarchical cluster tree: the Dynamic Tree Cut package for
  R. Bioinformatics, 24(5), 719-720.}

Friedman, J., Hastie, T. and Tibshirani, R. (2008)
  \emph{Regularization Paths for Generalized Linear Models via Coordinate
  Descent, \url{http://www.stanford.edu/~hastie/Papers/glmnet.pdf}}

Breheny, P. and Huang, J. (2011) \emph{Coordinate descent
  algorithms for nonconvex penalized regression, with applications to
  biological feature selection. Ann. Appl. Statist., 5: 232-253.}
}

